import numpy as np
from anndata import AnnData
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from matplotlib import pyplot as plt
import seaborn as sns
import pandas as pd

def mean_expression_in_grid(
    adata: AnnData,
    grid_size=100
    ) -> dict[dict]:

    """ Calculate the mean expression of genes withing each grid
    
    Parameters
    ----------
    adata
        Annotated data object.
        
    grid_size
        The desired grid size for averaging gene expression.
    """
    x_max = max(adata.obs['center_x'])
    y_max = max(adata.obs['center_y'])
    x_squares = int(np.ceil(x_max / grid_size))
    y_squares = int(np.ceil(y_max / grid_size))

    # Create a structure to store average expressions for each grid cell
    avg_expression_grid = [{} for _ in range(x_squares * y_squares)]

    # Extract expression matrix from AnnData
    expression_matrix = adata.X  
    # Populate the avg_expression_grid with average expression values for each gene
    for i in range(x_squares):
        for j in range(y_squares):
            k = i * y_squares + j
            x_min, x_max = i * grid_size, (i + 1) * grid_size
            y_min, y_max = j * grid_size, (j + 1) * grid_size
            
            # Filter indices for spots within current grid square
            spots_in_square_idx = np.where((adata.obs['center_x'] >= x_min) & (adata.obs['center_x'] < x_max) & (adata.obs['center_y'] >= y_min) & (adata.obs['center_y'] < y_max))[0]
            
            adata.obs.loc[adata.obs.index[spots_in_square_idx], 'grid_index'] = k

            # Convert the grid_index to integer type
            #adata.obs['grid_index'] = adata.obs['grid_index'].astype(int)
            if spots_in_square_idx.size:
                for gene_idx, gene in enumerate(adata.var_names):
                        
                    gene_expression_values = expression_matrix[spots_in_square_idx, gene_idx]
                    gene_expression_values = gene_expression_values[gene_expression_values > 0]
                    gene_expression_values = gene_expression_values[~np.isnan(gene_expression_values)]
                    

                    avg_expression_grid[k][gene] = np.mean(gene_expression_values)
    # Removes empty values
    avg_expression_dict = {k: grid for k, grid in enumerate(avg_expression_grid)}
    keys_to_remove = [k for k, v in avg_expression_dict.items() if not v]
    for k in keys_to_remove:
        del avg_expression_dict[k]
        
    return avg_expression_dict


def cluster_grid(
    avg_expression_dict,
    adata :AnnData,
    K : int
    )-> AnnData :
    
    """ Clustering the grid values with K-means 
    parameters
    
    avg_expression_dict
        list of dict with the average values of genes in each grid generated by the mean_expression_in_grid function
    
    adata
        Annotated data object.
    """
    
    all_genes = set()
    for k, cell in avg_expression_dict.items():
        all_genes.update(cell.keys())
    all_genes = list(all_genes)

    # Convert dictionaries to feature vectors and normalize
    X = []
    keys_in_order = sorted(avg_expression_dict.keys())  # Keep the keys in order
    for k in keys_in_order:
        cell = avg_expression_dict[k]
        feature_vector = [cell.get(gene, np.nan) for gene in all_genes]
        X.append(feature_vector)

    # Handle missing values (if any)
    X = np.array(X)
    X[np.isnan(X)] = 0  # Replace NaN with 0

    # Standardize the data
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Apply K-means clustering

    kmeans = KMeans(n_clusters=K, random_state=0)
    labels = kmeans.fit_predict(X_scaled)

    # Create a label dict corresponding to the original grid keys
    label_dict = {k: label for k, label in zip(keys_in_order, labels)}
    cluster_series = adata.obs['grid_index'].map(label_dict).astype('Int64')  # 'Int64' can hold both integers and NaNs
    adata.obs['Niche'] = cluster_series
    # Add the new Series as a column to adata.obs
    adata.obs['Niche'] = adata.obs['Niche'].astype('category')
    return adata


def niche_composition(adata):
    sns.set_theme(style="white")
    plt.rcParams['xtick.bottom'] = True
    plt.rcParams['ytick.left'] = True
    # Cross-tabulate the number of occurrences of each minor cell type in each cluster
    cell_type_counts = pd.crosstab(adata.obs['minor_cell_type'], adata.obs['Niche'])

    # Normalize the counts to get the percentagemi
    cell_type_percentage = cell_type_counts.div(cell_type_counts.sum(axis=1), axis=0) * 100

    # Plotting the heatmap
    plt.figure(figsize=(5, 10))
    sns.heatmap(cell_type_percentage, cmap='gist_heat_r', fmt='.1f', linewidths=.5, linecolor='gray', square=True)
    plt.title('Percentage of Cell Types in Each niche')
    plt.xlabel('Cell Type')
    plt.ylabel('niche')
    plt.show()